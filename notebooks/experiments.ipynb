{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_npz_file = np.load('../data/processed/train.npz')\n",
    "X_train, y_train = train_npz_file['arr_0'], train_npz_file['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19280, 105, 105), (19280, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 105, 105, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 105, 105, 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20'], dtype='<U41')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have an idea for a structure that constructs the type of dataset we want.  Create a dictionary with keys being the indices of the data, say.  \n",
    "\n",
    "For each of these, we maintain a 2d tuple\n",
    "- first element of this tuple is an array of indices of other (different) elements of the X, y.\n",
    "- the second element of the tuple is another array.  the element of this is 0 or 1 depending on whether the corresponding element of the first array of the tuple is a different or the same character as the current key of the dictionary.\n",
    "\n",
    "Then creating batches should be quite easy. And the size of the dictionary should control the corresponding size of the \"dataset\".  Accessing the structure to create batches should be fast and easy and we are just putting together access indices for X to form \"pairs\" and putting out the corresponding similarity labels.  \n",
    "\n",
    "We could further embelish with some random transformations of the corresponding X at the batch level.  See how this goes.  Let's get the bare-bones up and going first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class BatchSampler:\n",
    "    \"\"\"\n",
    "    Creates a batch sampler from raw-ish data pairs X, y.  The data needed for\n",
    "    training a siamese networks are image pairs from X and binary indicators\n",
    "    indicating whether they are equal.  Instead of forming these pairs explicitly,\n",
    "    this sampler creates a dictionary with keys corresponding to the rows of X.\n",
    "    The item stored at each key consists of a tuple with:\n",
    "        - a list of indices of rows of X to pair with the current key\n",
    "        - item a list of binary indicators inidcating whether they are of the same \n",
    "          type.\n",
    "    Although this takes a while to initialize (as initialization calls this pair\n",
    "    forming operation), this results in fairly efficient data storage, access and \n",
    "    batch construction.\n",
    "    \n",
    "    Attributes (this should probably be the actual attributes, not the entries\n",
    "    to __init__, which should be in the document there)\n",
    "    ----------\n",
    "    X : array\n",
    "        an n * h * w * n_channels array containing images, presumably from the \n",
    "        dataset we want to generate batches for (presumably for a siamese net\n",
    "        training task).\n",
    "    y : array\n",
    "        an n * 3 array containing the specifics of the characters in X.  The\n",
    "        columns are 'Alphabet', 'Character', 'Drawer'.  This makes this class\n",
    "        quite specific to omniglot.\n",
    "    batch_size : integer\n",
    "        this represents the size of the batches we ultimately want to generate.\n",
    "    half_expand_factor : integer\n",
    "        this represents half of the size by which we would like to expand the\n",
    "        dataset, or half of the number of pairs we would like to construct for\n",
    "        each row of X.\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    form_pairs() \n",
    "        forms the dictionary (this should probably be a private method as it is \n",
    "        called on initialization and not meant to be used.  Then it doesn't enter \n",
    "        into the docstring here or possibly at all).\n",
    "    \n",
    "    This is the general idea for forming these docstrings.  Description then \n",
    "    outline Attributes and public Methods.  Functions inside then have regular\n",
    "    style docstrings.  \n",
    "    \n",
    "    The way sampling is done here means we probably end up passing the same pairs\n",
    "    in here and there, but hopefully this won't hold things up too much.  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, X, y, batch_size=64, half_expand_factor=4):\n",
    "        self.X = X\n",
    "        self.y_n_pd = y # think on whether we really need this for what we want\n",
    "        self.y = pd.DataFrame(\n",
    "                        data=y,\n",
    "                        columns=['Alphabet', 'Character', 'Drawer']\n",
    "                    )\n",
    "        self.B = batch_size\n",
    "        self.E = half_expand_factor\n",
    "        self.n = y.shape[0]\n",
    "        self.pairs = self.form_pairs()\n",
    "        self.inds = np.random.permutation(y.shape[0])\n",
    "        self.current_batch = 0\n",
    "        self.current_efactor = 0\n",
    "        self.max_batches = 1 + y.shape[0] // batch_size\n",
    "        \n",
    "    def form_pairs(self):\n",
    "        pairs = {}\n",
    "        for i in range(self.n):\n",
    "            al, ch, dr = self.y.iloc[i]\n",
    "            same_inds = self.y[\n",
    "                    (self.y.Alphabet == al) &\n",
    "                    (self.y.Character == ch) &\n",
    "                    (self.y.Drawer != dr)\n",
    "                ].sample(self.E, replace=False).index.values\n",
    "            diff_inds = self.y[\n",
    "                   ~((self.y.Alphabet == al) &\n",
    "                     (self.y.Character == ch))\n",
    "                ].sample(self.E, replace=False).index.values\n",
    "            curr_y = np.zeros(2 * self.E)\n",
    "            curr_y[:self.E] = 1\n",
    "            p = np.random.permutation(2 * self.E)\n",
    "            pairs[i] = (\n",
    "                    np.concatenate((same_inds, diff_inds))[p],\n",
    "                    curr_y[p]\n",
    "                )\n",
    "        return pairs\n",
    "    \n",
    "    def generate_batch(self):\n",
    "        \"\"\"\n",
    "        Needs to be written.\n",
    "        \"\"\"\n",
    "        current_inds = self.inds[\n",
    "                    range(\n",
    "                        self.current_batch * self.B, \n",
    "                        min((1 + self.current_batch) * self.B, self.n)\n",
    "                    )\n",
    "        ]\n",
    "        X_b_inds, y_b = [], []\n",
    "        for ind in current_inds:\n",
    "            X_b_inds.append((ind, self.pairs[ind][0][self.current_efactor]))\n",
    "            y_b.append(self.pairs[ind][1][self.current_efactor])\n",
    "        X_b_inds = np.array(X_b_inds)\n",
    "        self.current_batch = (1 + self.current_batch) % self.max_batches\n",
    "        if self.current_batch == 0:\n",
    "            self.current_efactor = (1 + self.current_efactor) % (2 * self.E)\n",
    "        return (\n",
    "                (self.X[X_b_inds[:, 0],:], \n",
    "                 self.X[X_b_inds[:, 1],:]), \n",
    "                np.array(y_b)\n",
    "            )\n",
    "    \n",
    "    def generate_one_shot(self, n=20):\n",
    "        \"\"\"\n",
    "        Although this could also be a class that subclasses this.\n",
    "        \"\"\"\n",
    "        alphabet = np.random.choice(self.y.Alphabet.unique())\n",
    "        drawers = np.random.choice(\n",
    "                        self.y.Drawer.unique(), \n",
    "                        2, replace=False\n",
    "                    )\n",
    "        characters = np.random.choice(\n",
    "                        self.y[\n",
    "                            self.y.Alphabet == alphabet\n",
    "                        ].Character.unique(),\n",
    "                        n, replace=False\n",
    "                    )\n",
    "        \n",
    "        test_inds = self.y[\n",
    "                        (self.y.Alphabet == alphabet) &\n",
    "                        (self.y.Drawer == drawers[0]) &\n",
    "                        np.isin(self.y.Character, characters)\n",
    "                    ].index.values\n",
    "        \n",
    "        train_inds = self.y[\n",
    "                        (self.y.Alphabet == alphabet) &\n",
    "                        (self.y.Drawer == drawers[1]) &\n",
    "                        np.isin(self.y.Character, characters)\n",
    "                    ].index.values\n",
    "        return (\n",
    "                    (test_inds, train_inds), \n",
    "                    (self.y.iloc[test_inds], \n",
    "                     self.y.iloc[train_inds])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might change the name of this class to something like OneShotData, and have it do all the things we are interested in.  \n",
    "\n",
    "Another thing to do would be to have the option of caching a number of one-shot tasks for speed, so that we don't have to do the random sampling every time we call generate_one_shot on the object, as this is quite slow.  \n",
    "\n",
    "Or this might be easier with a separate OneShot generator.  \n",
    "\n",
    "The other thing that needs to be done is we need to build something that we can pass to a Bayesian optimization method...  Training is fast enough that we should be able to pick out something quite good in the next couple of days by optimizing on a couple of simple things like learning_rate and dropout rate by layer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a pandas data frame is quite a useful way to store the labels array for the sampling tasks that we require.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneShotGenerator:\n",
    "    \"\"\"\n",
    "    A class that generates one-shot tasks.  It does this in two\n",
    "    ways.  \n",
    "    - Caches a number of one-shot tasks and cycles through these.\n",
    "      this is the default mode.\n",
    "    - Randomly generates a one-shot task.  This is the mode that \n",
    "      should be used on test data, but is a little slow for the \n",
    "      purposes of model evaluation during training.\n",
    "    Also, the default is an 10-way one-shot task, because this\n",
    "    will be used on the training data, which has some alphabets\n",
    "    which have a small number of characters (I think 11 or 12 is\n",
    "    the smallest).  All alphabets in the test set have at least\n",
    "    20 characters, so 20-way evaluation here is fine.  \n",
    "        We could also default to 20-way and if an alphabet only\n",
    "    has m < 20 characters, then we fall back on an m-way challenge.\n",
    "    This might actually be better.  \n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, mode='cached', n_way=20, cache_size=320):\n",
    "        self.X = X\n",
    "        self.y_n_pd = y # think on whether we really need this for what we want\n",
    "        self.y = pd.DataFrame(\n",
    "                        data=y,\n",
    "                        columns=['Alphabet', 'Character', 'Drawer']\n",
    "                    )\n",
    "        self.mode = mode\n",
    "        self.n_way = n_way\n",
    "        self.cache_size = cache_size\n",
    "        self.cache = {}\n",
    "        self.form_cache()\n",
    "    \n",
    "        self.n = y.shape[0]\n",
    "        self.current_task_number = 0\n",
    "        \n",
    "    def form_one_shot(self):\n",
    "        \"\"\"\n",
    "        Although this could also be a class that subclasses this.\n",
    "        \"\"\"\n",
    "        alphabet = np.random.choice(self.y.Alphabet.unique())\n",
    "        # make sure that the number of tasks that we don't attempt\n",
    "        # to generate an n-way task when the alphabet is too small.\n",
    "        n = min(\n",
    "                self.n_way,\n",
    "                self.y.Character[\n",
    "                    self.y.Alphabet == alphabet\n",
    "                ].unique().shape[0]\n",
    "            )\n",
    "        \n",
    "        drawers = np.random.choice(\n",
    "                        self.y.Drawer.unique(), \n",
    "                        2, replace=False\n",
    "                    )\n",
    "        characters = np.random.choice(\n",
    "                        self.y[\n",
    "                            self.y.Alphabet == alphabet\n",
    "                        ].Character.unique(),\n",
    "                        n, replace=False\n",
    "                    )\n",
    "        \n",
    "        test_inds = self.y[\n",
    "                        (self.y.Alphabet == alphabet) &\n",
    "                        (self.y.Drawer == drawers[0]) &\n",
    "                        np.isin(self.y.Character, characters)\n",
    "                    ].index.values\n",
    "        \n",
    "        train_inds = self.y[\n",
    "                        (self.y.Alphabet == alphabet) &\n",
    "                        (self.y.Drawer == drawers[1]) &\n",
    "                        np.isin(self.y.Character, characters)\n",
    "                    ].index.values\n",
    "        return (\n",
    "                    (test_inds, train_inds), \n",
    "                    (self.y.iloc[test_inds], \n",
    "                     self.y.iloc[train_inds])\n",
    "        )\n",
    "    \n",
    "    def form_cache(self):\n",
    "        for i in range(self.cache_size):\n",
    "            self.cache[i] = self.form_one_shot()\n",
    "           \n",
    "    def generate_one_shot(self):\n",
    "        if self.mode == 'cached':\n",
    "            current_one_shot = self.cache[self.current_task_number]\n",
    "            self.current_task_number = (\n",
    "                    (1 + self.current_task_number) % self.cache_size\n",
    "                ) \n",
    "            return current_one_shot\n",
    "        return self.form_one_shot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pd = pd.DataFrame(data=y_train, columns=['Alphabet', 'Character', 'Drawer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_sample = np.random.choice(y_train_pd.Alphabet.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphabet</th>\n",
       "      <th>Character</th>\n",
       "      <th>Drawer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17441</th>\n",
       "      <td>Cyrillic</td>\n",
       "      <td>character20</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17785</th>\n",
       "      <td>Cyrillic</td>\n",
       "      <td>character24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17596</th>\n",
       "      <td>Cyrillic</td>\n",
       "      <td>character28</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17646</th>\n",
       "      <td>Cyrillic</td>\n",
       "      <td>character03</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17473</th>\n",
       "      <td>Cyrillic</td>\n",
       "      <td>character27</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Alphabet    Character Drawer\n",
       "17441  Cyrillic  character20     18\n",
       "17785  Cyrillic  character24     13\n",
       "17596  Cyrillic  character28     20\n",
       "17646  Cyrillic  character03     03\n",
       "17473  Cyrillic  character27     07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd[np.isin(y_train_pd.Alphabet, al_sample)].sample(5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphabet</th>\n",
       "      <th>Character</th>\n",
       "      <th>Drawer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17943</th>\n",
       "      <td>Cyrillic</td>\n",
       "      <td>character07</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17948</th>\n",
       "      <td>Cyrillic</td>\n",
       "      <td>character07</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Alphabet    Character Drawer\n",
       "17943  Cyrillic  character07     13\n",
       "17948  Cyrillic  character07     14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd[(y_train_pd.Alphabet == al_sample) & \n",
    "           (y_train_pd.Character == 'character07')].sample(2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_train_pd[(y_train_pd.Alphabet == al_sample) &\n",
    "           ((y_train_pd.Drawer == '13') | \n",
    "            (y_train_pd.Drawer == '12'))].sample(20, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([17591, 17472, 17914, 17739, 17419, 17432, 17736, 18032, 17615,\n",
       "            17633, 17933, 17934, 17648, 17594, 17885, 17572, 17551, 17857,\n",
       "            17475, 17940],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19280"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = y_train_pd.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Gujarati', 'character42', '14')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "al, ch, dr = y_train_pd.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Gujarati', 'character42', '16')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al, ch, dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 12,  3,  0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd[(y_train_pd.Alphabet == al) &\n",
    "           (y_train_pd.Character == ch) &\n",
    "           (y_train_pd.Drawer != dr)].sample(4, replace=False).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5790,  8971, 10339,   270])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd[~((y_train_pd.Alphabet == al) &\n",
    "            (y_train_pd.Character == ch))].sample(4, replace=False).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = BatchSampler(\n",
    "        X_train[:2500],\n",
    "        y_train[:2500],\n",
    "        batch_size=7,\n",
    "        half_expand_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, (7, 105, 105, 1), (7, 105, 105, 1), array([0., 1., 0., 1., 1., 1., 0.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b, c), d = a.generate_batch()\n",
    "a.current_batch, a.current_efactor, b.shape, c.shape, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tick_free_axis(ax, im):\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    ax.axes.get_yaxis().set_ticks([])\n",
    "    ax.imshow(1 - im, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 1. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAzTCAYAAABfVQhnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3V1u20i3QFHrIoPzkD2ozIHfQ4BctZLox9okq8i13hpIJ4rsiN44dcjLsiwfAAAAdP5v7xcAAABwNEILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACD245Vf/Pn5uXx9fa31WgAYy2XvFzAL10eAU3nq+vjSROvnz5/feykAcGCujwDccnQQAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYj/2fgHwyOVy2fslbG5Zlr1fAgAAbzDRAgAAiAktAACAmNACAACI2dFiCGfcw7rnnffDfhcAwP5MtAAAAGJCCwAAIOboIKtwFHA/t++9o4QAANsz0QIAAIgJLQAAgJjQAgAAiNnR4mn2ruZkZwsAYHsmWgAAADGhBQAAEBNaAAAAMTta/JOdrGOyswUAsD4TLQAAgJjQAgAAiAktAACAmB0tfpt1J+sIO0azvvcAAPydiRYAAEBMaAEAAMSEFgAAQMyO1smNuBt0hJ2rV736dx7x6wYAwP8z0QIAAIgJLQAAgJijgyez15GzMx4HBICRlD8DuK7DYyZaAAAAMaEFAAAQE1oAAAAxO1oknNUGgLF4FAjsy0QLAAAgJrQAAABiQgsAACBmR+vgnM8GgHNwzYexmGgBAADEhBYAAEBMaAEAAMTsaB3MluezPTsLAPZjJwvGZqIFAAAQE1oAAAAxoQUAABCzozU5O1kAcA52smAuJloAAAAxoQUAABBzdHACex0VcFQQAPa11c8ArvnQM9ECAACICS0AAICY0AIAAIjZ0eI357MBYF9u4Q7HYaIFAAAQE1oAAAAxoQUAABCzo3Vy9rIA4Hxc/2F9JloAAAAxoQUAABATWgAAADE7WgAAO1nzuVn2sGBfJloAAAAxoQUAABBzdPBkHCMAgGNyjYexmGgBAADEhBYAAEBMaAEAAMTsaE3AmWsAOIY1b+cOjMVECwAAICa0AAAAYkILAAAgZkcLAGAla+5k2eGGsZloAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxDxHCwAgtNazszw3C+ZiogUAABATWgAAADFHBwEABuW4IMzLRAsAACAmtAAAAGJCCwAAIGZHCwDgDWvdzh2Ym4kWAABATGgBAADEhBYAAEDMjhYAwCA8NwuOw0QLAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAg5jlaAAAvuFwue78EYAImWgAAADGhBQAAEHN0EABgJ8uy7P0SgJWYaAEAAMSEFgAAQExoAQAAxOxo8bS9bmfr/LpbCQPA35TXRz9vUDPRAgAAiAktAACAmNACAACI2dHin+wFHZMz6AAA6zPRAgAAiAktAACAmNACAACI2dGCAdmPAwCYm4kWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxNzenX9aluU//+2W43O6/ToCMI5H11af4TAvEy0AAICY0AIAAIgJLQAAgJgdLZ7mnPh67L8B8DfX1wfX4T95TxiZiRYAAEBMaAEAAMSEFgAAQMyOFhyM8+oA69rrOZOeuQVzMdECAACICS0AAICY0AIAAIjZ0YIdeG4WwHHstbN1yw4XjMVECwAAICa0AAAAYkILAAAgZkcLJufMPcBY7n0u77mje/1nu3bA+ky0AAAAYkILAAAg5uggbMQt3QEY9VbwjhJCz0QLAAAgJrQAAABiQgsAACBmRwsm5Cw9wDGMurN1y3UHXmeiBQAAEBNaAAAAMaEFAAAQs6MFADCIV3ahttzn8twteJ2JFgAAQExoAQAAxIQWAABAzI4WrGSvZ6EAcA6jPIML+DsTLQAAgJjQAgAAiDk6CBFHNgDY05ZHCa9/b7d6/1P53nt/52WiBQAAEBNaAAAAMaEFAAAQs6MF32QnC4CR3dvtcQ2D9ZloAQAAxIQWAABATGgBAADE7GjBBDxDAwBgLiZaAAAAMaEFAAAQE1oAAAAxO1rwpC2fOWInC4BZ3F4fXcNa1++v93YuJloAAAAxoQUAABATWgAAADE7WnDHWntZzlgDsKfb69CWe8hwFiZaAAAAMaEFAAAQc3QQrjg6AQC86/poZvmzhVvpz8VECwAAICa0AAAAYkILAAAgZkcLNuIcNQCcj1vpn5eJFgAAQExoAQAAxIQWAABAzI4Wp7bmOWk7WQCMyp4QrM9ECwAAICa0AAAAYkILAAAgZkeLU7GTBcBZrXUNdP3bz+3X1NdiLCZaAAAAMaEFAAAQE1oAAAAxO1ocmueEAHBWroFjut2j8nU6LhMtAACAmNACAACIOTrI4Ww1gncLVQD2tOeRM9dAeMxECwAAICa0AAAAYkILAAAgZkeL6dnJAuCoRrn1t2sgvM5ECwAAICa0AAAAYkILAAAgZkeL4Y1yPh0AaqNe4+xkbef2vX7ne+L2//V13JeJFgAAQExoAQAAxIQWAABAzI4WQ3BGHYAjGvX6dsv1DnomWgAAADGhBQAAEBNaAAAAMTtabMIZdQDOYtRrnmscbMtECwAAICa0AAAAYo4OsgrHJgA4Ktc44BkmWgAAADGhBQAAEBNaAAAAMTtaJEY6r+6MOgClka5x11zvYGwmWgAAADGhBQAAEBNaAAAAMTtaTM8ZdQDeZQ8LqJloAQAAxIQWAABATGgBAADE7GjxT86rA3BUo1zjXNPguEy0AAAAYkILAAAg5uggv41yjOKRvV6n4x0AvMq1A87LRAsAACAmtAAAAGJCCwAAIGZH6+Rm2csCgHdseb2zl8VefO+NxUQLAAAgJrQAAABiQgsAACBmR+tk7GQBcAZ2spjVve+n2+9r33tjM9ECAACICS0AAICY0AIAAIjZ0To4O1kd56IB+Pjw+c9+fO/NxUQLAAAgJrQAAABiQgsAACBmR+vgZjzLO8temZ0tgLGsdf3w+Q58h4kWAABATGgBAADEHB1kOGse0VjzWKKjhADbWvMz3Wc48C4TLQAAgJjQAgAAiAktAACAmB0tTuX2zL2dLQA+PnxGAz0TLQAAgJjQAgAAiAktAACAmB0t2Mj1zpZdAIDXlXu1PoeBtZloAQAAxIQWAABATGgBAADE7Ghxao/O6NsHANiPz2BgZiZaAAAAMaEFAAAQE1oAAAAxO1oAwOHYyQL2ZqIFAAAQE1oAAAAxRwfhjntHT8rbDgPw/ueq44LASEy0AAAAYkILAAAgJrQAAABidrTgm253AexsAbzunc9OO1nAyEy0AAAAYkILAAAgJrQAAABidrQgYlcAYF0+Z4GZmGgBAADEhBYAAEBMaAEAAMTsaAEAm3nluVl2soCZmWgBAADEhBYAAEBMaAEAAMTsaAEAq7GTBZyViRYAAEBMaAEAAMQcHQQAduO4IHBUJloAAAAxoQUAABATWgAAADE7WgBA5tHt3O1kAWdhogUAABATWgAAADGhBQAAELOjBQB8m50sgL8z0QIAAIgJLQAAgJjQAgAAiNnRAgAydrIAfjHRAgAAiAktAACAmNACAACI2dECAL7NThbA35loAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABA7LIsy/O/+HL5Wpblc8XXAwDTcX0E4NZLoQUAAMBjjg4CAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABA7Mcrv/jz83P5+vpa67UAMJbL3i9gFq6PAKfy1PXxpYnWz58/v/dSAODAXB8BuOXoIAAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxH7s/QL40+VyefrXLsuy4isBAAC+w0QLAAAgJrQAAABiQgsAACBmR2sAr+xkPfp/7WwBAMD+TLQAAABiQgsAACDm6ODBOEoIAAD7M9ECAACICS0AAICY0AIAAIjZ0To4O1sAALA9Ey0AAICY0AIAAIgJLQAAgJgdrQHc7k3d7lUBAABzMdECAACICS0AAICY0AIAAIjZ0RrQmjtbnqsFAADrM9ECAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNu7T2Cr27271fu6Xvm6+VoAAMzNRAsAACAmtAAAAGJCCwAAIGZHi99ud4jsCb3nnV26cg+v5HsCAOA5JloAAAAxoQUAABATWgAAADE7WhO63pMZdZeHY7LHBwDwHBMtAACAmNACAACICS0AAICYHa3J3e7I2NkCAID9mWgBAADEhBYAAEDM0UH+ya283+NYJwDAeZloAQAAxIQWAABATGgBAADE7GgdzJp7QXa23nP9ftnXAoCxVddqPy+dl4kWAABATGgBAADEhBYAAEDMjhbfdn122fnj1+z5ftkPAwBYn4kWAABATGgBAADEhBYAAEDMjtbBrflcrXu/r50tAADOzEQLAAAgJrQAAABiQgsAACBmR4tVPNoFs8MFAIzEcyapmWgBAADEhBYAAEDM0cGT2ep274+4HTwAAEdmogUAABATWgAAADGhBQAAELOjdXLXu1F73tb0+s+2rwXAzMrrqWvinHzd+Pgw0QIAAMgJLQAAgJjQAgAAiNnR4rdH54m32uF69Oc49wwAwOhMtAAAAGJCCwAAICa0AAAAYna0eNq93agtn8F1+2fZ2QIAYDQmWgAAADGhBQAAEBNaAAAAMTtaJG73pPbc2bpmfwsAgD2YaAEAAMSEFgAAQMzRQVax51HCe3+uo4QAAGzBRAsAACAmtAAAAGJCCwAAIGZHi0082o3aaofLzhYAAFsw0QIAAIgJLQAAgJjQAgAAiNnRYgjXu1J7PXMLAAAqJloAAAAxoQUAABATWgAAADE7Wgzn9tlWdrYAAJiNiRYAAEBMaAEAAMSEFgAAQMyOFsOzs/Ue7xcAwPZMtAAAAGJCCwAAIOboIPC022OcADArR+tZm4kWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQOzH3i8AAABmtizL3i+BAZloAQAAxIQWAABATGgBAADE7GjBwVwul71fAgDA6ZloAQAAxIQWAABAzNFB4J/crhYA4HtMtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGKeowWTu1wu2e/luVkAAA0TLQAAgJjQAgAAiAktAACAmB0tAAAOr9xphmeYaAEAAMSEFgAAQMzRQYZn1A8AwGxMtAAAAGJCCwAAICa0AAAAYna0vqncG1qWJfu9AABYd8fbz248w0QLAAAgJrQAAABiQgsAACBmR4vhOFMNAHyHZ28yEhMtAACAmNACAACICS0AAICYHa0B3J4ntkfUOep76Qw6AGx3PTzqzxOsy0QLAAAgJrQAAABiQgsAACBmR2tAdrbYku8vAICeiRYAAEBMaAEAAMQcHZzAvVuXznrsy+3JX+P9AoBtr4ez/ozFOEy0AAAAYkILAAAgJrQAAABidrS+6dG53a3OELsV/J/uvQd2nf7kPTk3nxkAv/g8pGaiBQAAEBNaAAAAMaEFAAAQs6O1kttzvvZgtuO9hufZ8wRGsuc13M8P2znLtcZECwAAICa0AAAAYkILAAAgZkdrI9dnUdc8A2zfAgAYmV0o3vkemOlnWxMtAACAmNACAACICS0AAICYHa0dbPmMLeegARiZ69R93h/4r5nuR2CiBQAAEBNaAAAAMUcHB7DlUUKAayMfuQCAmZloAQAAxIQWAABATGgBAADE7GgNyM7WduynAACwBhMtAACAmNACAACICS0AAICYHS0Ox94VAHDLzwf7Ke83MNPX0UQLAAAgJrQAAABiQgsAACBmR2sCZ3+u1kxncQGA19y7zp/tZ56jOuvPciZaAAAAMaEFAAAQE1oAAAAxO1oTOus5VwCO5+jXtFd3jI7+fsCZmGgBAADEhBYAAEDM0UEAgJU4Cviedx5x471nbyZaAAAAMaEFAAAQE1oAAAAxO1oAAEzB3hUzMdECAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAIDYZVmW53/x5fK1LMvniq8HAKbj+gjArZdCCwAAgMccHQQAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACI/XjlF39+fi5fX19rvRYAxnLZ+wXMwvUR4FSeuj6+NNH6+fPn914KAByY6yMAtxwdBAAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACI/dj7BQAAMJbL5fKf/16WZadXAvMy0QIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY27sDAJzc7e3cgfeZaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMQ8RwsA4GQ8NwvWZ6IFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMbd3BwA4Abd0h22ZaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMQ8RwsA4IA8Nwv2ZaIFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAALEfe78AAADed7lc9n4JwBUTLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjnaAEA8B/Lsuz9EmB6JloAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxz9ECAJjQ5XLZ+yUAd5hoAQAAxIQWAABAzNFBAIAJrHlUcFmW1X5vOCsTLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjnaAEAnIznZsH6TLQAAABiQgsAACAmtAAAAGJ2tIB/ulwu2e9lHwDgdeXnMLAtEy0AAICY0AIAAIgJLQAAgJgdrZNZ66y3/Zv3nOEMvn0vgH357IRtmWgBAADEhBYAAEDM0cEJneGY2RH5unUevZeOxwCzcq2A4zDRAgAAiAktAACAmNACAACI2dEagPPY0Lr+N2VfCzgrn3+wLxMtAACAmNACAACICS0AAICYHa0d2MmC7dz+e7OzAIzEzwRwXCZaAAAAMaEFAAAQE1oAAAAxO1orOduZa3swx1R+HUf5N+F7FQDYgokWAABATGgBAADEHB08mXvHpMqjXY9+L8e13jPj+/fOa17z2KHvVWBLa36e+byCsZhoAQAAxIQWAABATGgBAADE7GhNbtbz2Ge8xfYZ/o5ruX3vtrxV/PWf5WsIjMRnEozNRAsAACAmtAAAAGJCCwAAIGZHawJbncG2B8Ms9vpePeNuIQDwPSZaAAAAMaEFAAAQE1oAAAAxO1r80547W/AKO1vAqFw74bxMtAAAAGJCCwAAICa0AAAAYna0VnLEXY17f6fyDLq9F9611fcqwJZcD2EuJloAAAAxoQUAABBzdJCEW8EzizW/Vx17BT4+1rsGjnRt9fkGj5loAQAAxIQWAABATGgBAADE7GgBp2a/EOB19z4r7W/BLyZaAAAAMaEFAAAQE1oAAAAxO1oAAGQ8UxB+MdECAACICS0AAICY0AIAAIjZ0QIAeIPn79336P2xw8VRmWgBAADEhBYAAEBMaAEAAMTsaAGsxLNkAB67/qz0OcmRmGgBAADEhBYAAEDM0UGG5/gVACMZ9Xbua14ft/o7u+ZzJCZaAAAAMaEFAAAQE1oAAAAxO1qs4vZMdXm22/lt1rTV967vW+DjY57PgjU/G+9xzWdmJloAAAAxoQUAABATWgCme5LVAAAgAElEQVQAADE7WkzP+W0A2Na9a+2a+1uPfm8/AzASEy0AAICY0AIAAIgJLQAAgJgdLTax1/M34F3X37ueBwfn5Jr1mj2v+Z5XyEhMtAAAAGJCCwAAICa0AAAAYna02MWa57edz2Ytdg3hPNb6933G65LPTs7KRAsAACAmtAAAAGKODjIEt9Dm7P7H3r0lN44kCRSVzGpxueRcVO2B/VE2PWyWks8LIAJxzt/YVEuUyCR0LdwJr1VgFXuNEnpf5WhOtAAAAGJCCwAAICa0AAAAYna0AN7kI4vhPHyc+3G22tO+ZWeLvTnRAgAAiAktAACAmNACAACI2dFiOFvuvZjPBmBrri3v23P31d8EbM2JFgAAQExoAQAAxIQWAABAzI4Ww7OzBUDNfe/mYGeLmTnRAgAAiAktAACAmNACAACI2dGCK+azAXiVa8V+jtrZ8hzzDidaAAAAMaEFAAAQMzrIdPYcGwDgHFwrzmmvvwmsFvAOJ1oAAAAxoQUAABATWgAAADE7Wkxvy/lsH+0KwC3Xg3FdPzd7ffT77feF/+NECwAAICa0AAAAYkILAAAgZkeL09lqPts8NgDMY8/7bvobgZ840QIAAIgJLQAAgJjQAgAAiNnRgjeZxwYYV7mP4/2dV917/Xk9rcOJFgAAQExoAQAAxIwOcmpHfrTro8eyGqOWABxpz78J7vH3wjqcaAEAAMSEFgAAQExoAQAAxOxo8Udn/GjcI+ezV/uo10e/29V+H8D2jtq5YU6PrjVeT3zKiRYAAEBMaAEAAMSEFgAAQMyOFksb9Z4aM+4omWUH9rbl+86M78O0rl8DR+50ey3Oy4kWAABATGgBAADEhBYAAEDMjhZcsbM1hll+fntpAGsY5e8D5uJECwAAICa0AAAAYkILAAAgZkcL7ri3G3TkPTWujbK/ZH79M6M8jzAy981iFI9eL66BfH050QIAAMgJLQAAgJjRQXjTKGMDj77PXuMwxiQA4B/X195Xr4/GWM/DiRYAAEBMaAEAAMSEFgAAQMyOFn9kRvgzo3zc+Svf99XnfKufyWsP+Pryce6cg9faupxoAQAAxIQWAABATGgBAADE7GjBTj65p8ZeRn1cAJ+yJwPszYkWAABATGgBAADEhBYAAEDMjhYc4NGugF0pAIC5OdECAACICS0AAICY0AIAAIjZ0YIBrbjD5R43QPne5j0FOJoTLQAAgJjQAgAAiBkdhAndG4mZZazQWA8AcGZOtAAAAGJCCwAAICa0AAAAYna04GRG/Wh4O1nAT2bZKwV4lRMtAACAmNACAACICS0AAICYHS1YjF2p99klgbF5fwNG4kQLAAAgJrQAAABiQgsAACBmRwvgSbf7H5/sbNklYVV2HYFVONECAACICS0AAICY0AIAAIjZ0QIApmTXERiZEy0AAICY0AIAAIgZHQR4k7EleMzHuQOrcqIFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQcx8tACDjvlkA/3CiBQAAEBNaAAAAMaEFAAAQs6MFALxtz52sy+Wy2/cC+JQTLQAAgJjQAgAAiBkdBACGZFQQmJkTLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJj7aAEAb7u919X39/dH/3uAs3CiBQAAEBNaAAAAMaEFAAAQs6MFAGTsXAH8w4kWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEDs+3K5PP8ff3//vlwuvzZ8PAAwHddHAG69FFoAAAA8ZnQQAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYn+98h//+vXr8vv3760eCwBj+T76AczC9RFgKU9dH1860fr777/feygAcGKujwDcMjoIAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABD76+gHAJzD9/d39rUul0v2tQAAjuBECwAAICa0AAAAYkYHgbeV44IAAGfiRAsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACDmPlqLKe97dLlcsq/FmNwnCwDgPU60AAAAYkILAAAgJrQAAABidrSA/7KTBQDQcKIFAAAQE1oAAAAxoQUAABCzowWLO2ovy33YAIAzc6IFAAAQE1oAAAAxo4O87XrkzBgYj3iNAAArcaIFAAAQE1oAAAAxoQUAABCzo0Xi9iPC7eOsx3MOAPD/nGgBAADEhBYAAEBMaAEAAMTsaC3mdo/mdreqYmcLgJ+U1x3XFmBkTrQAAABiQgsAACAmtAAAAGJ2tBZ3Pd++1b4WY/E8A2dx7/3M/hZwNCdaAAAAMaEFAAAQE1oAAAAxO1r815b32HJfrXPyPAKjenQN8/4FbM2JFgAAQExoAQAAxIwO8kdGCQE4K9chYGtOtAAAAGJCCwAAICa0AAAAYna0AIDl3dtDtr8FvMOJFgAAQExoAQAAxIQWAABAzI4WT9vrvlpm4QHO65X3+PI68wn33ALe4UQLAAAgJrQAAABiQgsAACBmR4u3Xc+ob7Wvdft9AFjHq+//e+10uU5xq3zteT2dhxMtAACAmNACAACICS0AAICYHS2GZxYegGdstTsM8A4nWgAAADGhBQAAEDM6SOJ2nM/IBgBHejRm7rYkwNacaAEAAMSEFgAAQExoAQAAxOxosYktd7bMwgPwqb2uU65RsC4nWgAAADGhBQAAEBNaAAAAMTta7MLOFgBwFu4XyjOcaAEAAMSEFgAAQExoAQAAxOxoAQDL22qX2B7xOWy5k+U1cV5OtAAAAGJCCwAAIGZ0kEPs9XHvjuMBeMf19cMtSYB3ONECAACICS0AAICY0AIAAIjZ0WIIW83CA8DI7GyNa6u/RzzH63CiBQAAEBNaAAAAMaEFAAAQs6PFqZl9B+BTW977kXHYyaLmRAsAACAmtAAAAGJCCwAAIGZHi+FsOQtvZwuAT7lOAc9wogUAABATWgAAADGhBQAAELOjxdLMwgPwqb12tlyj5uG54uvLiRYAAEBOaAEAAMSMDjK8LUcyAIA1+XuCrTnRAgAAiAktAACAmNACAACI2dFiOnt9jO5P3wsAHrm+drhGjWPLnSzPBT9xogUAABATWgAAADGhBQAAELOjxfTcZ+s+vw+A47hGwbqcaAEAAMSEFgAAQExoAQAAxOxowR3Xs/TukQHASNxX6z73zeJoTrQAAABiQgsAACAmtAAAAGJ2tDid67lp9ytpmUkH+MyW99Wys7Udv0ve4UQLAAAgJrQAAABiRgcnV44cOBZnS16rAMBKnGgBAADEhBYAAEBMaAEAAMTsaAEAHMTHvbfc1oWRONECAACICS0AAICY0AIAAIjZ0QIAGMSWO1u8ZoWdNrblRAsAACAmtAAAAGJCCwAAIGZHCwBgAdf7XmfZP7LDxsicaAEAAMSEFgAAQExoAQAAxOxoAQAM6nqXyj7Stj7ZW5vluTnLbt4snGgBAADEhBYAAEDM6ODkHAEzi9vX6itjFl7nAHx9jTOiN8rjeNUZP+J/ZE60AAAAYkILAAAgJrQAAABidrSAQ5gNB+BIq1+HbvfMVv99bMGJFgAAQExoAQAAxIQWAABAzI4WAAC84JN7Q7IOJ1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAx99ECAIAPnOG+WreP+fZn4nVOtAAAAGJCCwAAIGZ0EAAAQtdjdzOOEdJwogUAABATWgAAADGhBQAAELOjBQDAkM6w3/ToY9JH+Rl9nHvPiRYAAEBMaAEAAMSEFgAAQMyOFgAApzfqDtIrj6vc5xr193EmTrQAAABiQgsAACAmtAAAAGJ2tDidUe5HAQBQslc1FydaAAAAMaEFAAAQMzoIAIvb8iOjfRw1sConWgAAADGhBQAAEBNaAAAAMTtacId9AAAA3uFECwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAIOY+WgCwmO/v76MfAsDpOdECAACICS0AAICY0AIAAIjZ0QKAxVwul//5v+1sAfScaAEAAMSEFgAAQMzoIADwttsxxEf//1fGFB99bXjF7WvP64utOdECAACICS0AAICY0AIAAIjZ0WJ6PpYY4DN77qrYiwFW4UQLAAAgJrQAAABiQgsAACBmRwsAgCF9ch+2R9xXi6050QIAAIgJLQAAgJjQAgAAiNnRYjpb3jfLfDYArMnOFjUnWgAAADGhBQAAEBNaAAAAMTtaDG/LnSxeY34dgCNteV8tqDnRAgAAiAktAACAmNFBhrPnGIDRNwD2ZNRtHtfPlb8XeIcTLQAAgJjQAgAAiAktAACAmB0thrDXzPqKM9Y+ChdgX95n93Pvul4+D25vwjucaAEAAMSEFgAAQExoAQAAxOxocQg7WefgHiPAimbdwfI+3bGzxTOcaAEAAMSEFgAAQExoAQAAxOxosYs959nNSR/DvDows1n3ru5Z/X14z/tIugbyEydaAAAAMaEFAAAQE1oAAAAxO1pswk7WuPacWQcYxRnf61z/XuP6x96caAEAAMSEFgAAQMzoIAmjgvO6/n2Wz+OrX8vzCtxaYbTLe99xthwlvPe1POfrcKIFAAAQE1oAAAAxoQUAABCzo8Xb9pqdN8u8hldeT14TMK8V9q6ueb+ax14f/377db1GzsuJFgAAQExoAQAAxIQWAABAzI4WT7OTdX57zad/qnxcXm/Ap7yP8Ak7W+flRAsAACAmtAAAAGJCCwAAIGZHiz8adT8HALZmT4br18CefxPd+15el3NxogUAABATWgAAADGjg4s7ajzQ0fccHj1PxkuBWbju8IlRbn/io+Dn4kQLAAAgJrQAAABiQgsAACBmR2sxdrIoffK82u+CNZW7Lq4tHMUOM89wogUAABATWgAAADGhBQAAELOjxSbMzfPIvdfIlrPtXpswFv8mOaPr13V5TfPvZS5OtAAAAGJCCwAAICa0AAAAYna0SJgZplTeZwcAjvTpNc3fWPNyogUAABATWgAAADGhBQAAELOjxdvMDLMXrzUAzsI1bR1OtAAAAGJCCwAAIGZ0cDGOqwEAYHtOtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAIPZ9uVye/4+/v39fLpdfGz4eAJiO6yMAt14KLQAAAB4zOggAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAACxv175j3/9+nX5/fv3Vo8FgLF8H/0AZuH6CLCUp66PL51o/f333+89FAA4MddHAG4ZHQQAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACA2F9HPwAAANja9/d39rUul0v2tTgvJ1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABD76+gHAAAAte/v76MfAotzogUAABATWgAAADGhBQAAELOjBQCczpH7OZfL5bDvDYzDiRYAAEBMaAEAAMSMDgIAQ5rl47mNCp6f55h3ONECAACICS0AAICY0AIAAIjZ0QIADjPLHtY1+zrAM5xoAQAAxIQWAABATGgBAADE7GgBAJkZd64esZMFvMOJFgAAQExoAQAAxIQWAABAzI4WAPC2M+5k3br9Ge1sAc9wogUAABATWgAAADGhBQAAELOjBQC8ZIW9rHvsbAHPcKIFAAAQE1oAAAAxo4MMoRxDMcIBsIZX3u+3HHc0Sgj8xIkWAABATGgBAADEhBYAAEDMjhYAMIQtd5tuv/ZeO1v2tWBdTrQAAABiQgsAACAmtAAAAGJ2tACAwxy1w7TXzpZ7bMG6nGgBAADEhBYAAEBMaAEAAMTsaHE67l8CwKvsbAE1J1oAAAAxoQUAABATWgAAADE7Wk/aalZ7a7PMfl8/zll/1wC8btS92r2uS3a24LycaAEAAMSEFgAAQGzp0cEVRtRWH0lY/ecH4HN7ffT7T1/bdQvm5UQLAAAgJrQAAABiQgsAACC21I7WCjtZj5j9BuBTq9+S46idLddsmIsTLQAAgJjQAgAAiAktAACA2FI7WvzbarPfdtQAqO21s+UaBnNxogUAABATWgAAADGhBQAAEDv1jtaK9/YAgFmdZQdpr/uMneX3BWflRAsAACAmtAAAAGKnHh3c0ijH82ccj9zrY3J/+tqjPK8As9jzPXtGfj+wLidaAAAAMaEFAAAQE1oAAAAxO1pPWmF3x76S3wHASLwnAzNzogUAABATWgAAADGhBQAAELOjNTn35wBgFWfY2XLdhnU40QIAAIgJLQAAgJjQAgAAiNnR4o9GmYU/cp79+nvNuAsAsLc937NHuU4B/MSJFgAAQExoAQAAxIQWAABAzI7WyWw5G28WHoBXHbWz5RoFHM2JFgAAQExoAQAAxIwOTmDPjzPnz4xOAnzuyFt2jGC1nxdW5kQLAAAgJrQAAABiQgsAACBmR4vprD7fD3Am1+/pW96S5N73BdiCEy0AAICY0AIAAIgJLQAAgJgdLaZ31M6W+2oBtPZ8P99rh2vLn8F1B8bmRAsAACAmtAAAAGJCCwAAIGZHCwBgAnayYC5OtAAAAGJCCwAAICa0AAAAYna0IOK+WgCto+6TCFBwogUAABATWgAAADGjgxO4N4JmjOLfrn9fR/5+jBICtB69j45yTRzlcQDHcqIFAAAQE1oAAAAxoQUAABCzozU5H31730i/n+vvbV8LAODcnGgBAADEhBYAAEBMaAEAAMTsaAEAp3DU/qv9aOAnTrQAAABiQgsAACAmtAAAAGJ2tJ50O389yn2QzIXPadTXEwCP7XntdX2AeTnRAgAAiAktAACAmNACAACI2dF6k90oADiPUa7rdrLgPJxoAQAAxIQWAABAzOggTzPOsB0f9w6wrVFGA295v4fzcqIFAAAQE1oAAAAxoQUAABA79Y7W7dzzqPPZAEBr1Gu+nSxYhxMtAACAmNACAACICS0AAIDYqXe0btnZeo058vu2fD25rxbA60a8rnv/hnU50QIAAIgJLQAAgJjQAgAAiC21o3Xr0dz0iLPeALCqWa7L9rKAry8nWgAAADmhBQAAEBNaAAAAsaV3tB4ZdcZ6lhn11bivFsBnRr2+ec/FdZh3ONECAACICS0AAICY0cEJ7DVK4RgcgL2NMi7oGgjUnGgBAADEhBYAAEBMaAEAAMTsaA1oz3l1M+nb2evj3j2HwMhG2cG65b0T2JoTLQAAgJjQAgAAiAktAACAmB2tAdjJAmAmo+5dXXO9A47mRAsAACAmtAAAAGJCCwAAIGZH6wAzzLafRfm7/nTe//p/7zUAzGSW9yx7WWz1WvXa4h1OtAAAAGJCCwAAIGZ0cCdHjV046j6/29eW5xz41Kijgt7fOIprLe9wogUAABATWgAAADGhBQAAELOjtRE7WccZdbfg2u3zNMNjBs5rlPcg1zBeNcprF37iRAsAACAmtAAAAGJCCwAAIGZHK7LnjLAZ9v34XQO0vK/yiVF2stxXi2c40QIAAIgJLQAAgJjQAgAAiNnRetMoM8J4Lm6ZGweO5D0H4B9OtAAAAGJCCwAAICa0AAAAYna0royy62O+/Thn/N3b2QJgVqP8bQbvcKIFAAAQE1oAAACx6UYHz3iEbJTrNSu8Brb8GY0SAjCqM17jWZcTLQAAgJjQAgAAiAktAACA2PA7Wmec1bUTM45Rn4ujdrZG/X0AMI9R/3bb8tpq/5mfONECAACICS0AAICY0AIAAIgNt6M16lzvp8zqvu+sr4lX7LWzNeqM+Sc/7yg/A8DMzngt3nMfmjU50QIAAIgJLQAAgJjQAgAAiA23ozXrvKw9kM6Wz7nn6TV2o4BXed+Ywyx/X83KPSr5+nKiBQAAkBNaAAAAMaEFAAAQG25H69aoO1vmbTnSvdffKP9GRnkcwDwevW+49vKKV18vo/7NybycaAEAAMSEFgAAQGz40QOrA/AAAB5OSURBVMFboxzrGm/4zF7P24rPwyj/RgBqbv/xmRmvBys8L5yXEy0AAICY0AIAAIgJLQAAgNh0O1q3Rt1Hufc4zBtvy+/3f436bwQYh/eJNX/mvax+XbZbuC4nWgAAADGhBQAAEBNaAAAAsel3tG7dm1UdZf66fByjzuaO8rvm3+xiAI94n+AVo/4t8qnrn2vUfwO3j+usz8WsnGgBAADEhBYAAEBMaAEAAMROt6N1z6O51VHnb++Z8THXzCN/pvr9jfRa9JqAVvlvaqT3Cp7nfXUOdrbG4kQLAAAgJrQAAABiQgsAACC21I7WIzPcgwvzxqPyvADPeOW9wrX3ON7T/5d7y/EOJ1oAAAAxoQUAABAzOvikM340/CyMLwCsacv3/9Wv266tnxl1lNDzOhYnWgAAADGhBQAAEBNaAAAAMTtaETtcHfPFAGzNtYaS1xM/caIFAAAQE1oAAAAxoQUAABCzo7WTcnb3DPteZpkBADgzJ1oAAAAxoQUAABATWgAAADE7WhOy3wQAAGNzogUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAA/2nvjnIax7YAipYlBseQGVTNwe+j1a3g4iWk2M69ttf6aiQK3CDhbJ17YogJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACA2LKu6/c/eVk+1nV93/F6AOBw3B8B2HoqtAAAAHjM0UEAAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACA2Nszn/z+/r5+fHzsdS0AzGUZfQFH4f4IcCnfuj8+NdH6/fv3310KAJyY+yMAW44OAgAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxN5GXwDXsCzLbl97XdfdvjYAAPwNEy0AAICY0AIAAIgJLQAAgJgdLQ7v3v6X/S0AAEYw0QIAAIgJLQAAgJijg5zas28r76ghAAAFEy0AAICY0AIAAIgJLQAAgJgdLbjhreIBACiYaAEAAMSEFgAAQExoAQAAxOxowTc9eiaXHS4AAP5logUAABATWgAAADGhBQAAELOjxUs8s7/0aBdqVs9ct30uAIBzM9ECAACICS0AAICY0AIAAIjZ0WI6z+4vHXGnyzO5AADOzUQLAAAgJrQAAABijg5yePeO2R3xWOGvX44WAhxZee/x9x6Oy0QLAAAgJrQAAABiQgsAACBmR4tTe3S2/Qw7XM7vA5zXvfuUv/8wNxMtAACAmNACAACICS0AAICYHS0u7aw7XACcn2cuwtxMtAAAAGJCCwAAICa0AAAAYna04I5nzrfb5wJgJp7BBWOZaAEAAMSEFgAAQExoAQAAxOxoQcQzuQA4iu09yc4W9Ey0AAAAYkILAAAg5uggvMjtsQzHCAHO6yfH8EbdHx59X0cL4XkmWgAAADGhBQAAEBNaAAAAMTtaAACTuLcLNXK/19vBw/NMtAAAAGJCCwAAICa0AAAAYna0AAAO4NFelGc0wlxMtAAAAGJCCwAAICa0AAAAYna0AABOYLvDtefO1u3X9kwt+JqJFgAAQExoAQAAxBwdBAA4oVceJQT+ZKIFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQ8xwtAIALuH2ulmdqwf5MtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAg9jb6AoCfWZbl08frug66EgAA/mWiBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADFv7w4DbN+CffsW7QAAHJuJFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxN5GXwDQWpbl08frug66EgCA6zLRAgAAiAktAACAmNACAACI2dGCCWz3qLZ7VgAAHIuJFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABA7G30BQD7Wpbl08frug66EgCA6zDRAgAAiAktAACAmNACAACI2dGCCW33qLZ7VgAAzM1ECwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJvoy8AeK1lWT59vK7roCsBADgvEy0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY52jBAWyfdbV9FhYAAHMx0QIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACA2NvoCwDGWpblv/9e13XglQAAnIeJFgAAQExoAQAAxIQWAABATGgBAADEhBYAAEBMaAEAAMSEFgAAQExoAQAAxIQWAABATGgBAADE3kZfAPC8dV3/++9lWQZeCQAAXzHRAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIi9jb4AYB7Lsnz6eF3XQVcCAHBsJloAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAsbfRFwD8zLqunz5elmXQlQAA8C8TLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIh5e3c4OG/nDgAwHxMtAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgNjb6AsAfmZd108fL8vyo38PAMDPmWgBAADEhBYAAEDM0UE4GUcBAQDGM9ECAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiAktAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiL2NvgAAAF5rXddPHy/L8qN/D/zJRAsAACAmtAAAAGJCCwAAIGZHCwDg4uxcQc9ECwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYsu6rt//5GX5WNf1fcfrAYDDcX8EYOup0AIAAOAxRwcBAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAgJrQAAABiQgsAACAmtAAAAGJCCwAAICa0AAAAYkILAAAg9vbMJ7+/v68fHx97XQsAc1lGX8BRuD8CXMq37o9PTbR+//79d5cCACfm/gjAlqODAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAsbfRF8BYy7Ls8nXXdd3l6wIA8LWfvK7z2q1nogUAABATWgAAADGhBQAAELOjdXJ77WA9+32d+/2Z8vfodwHAWY163QNfMdECAACICS0AAICY0AIAAIjZ0To4Z5F5lv05AI7K6x6OxEQLAAAgJrQAAABiQgsAACBmR2sCVzhvbC8IAHjWFV4jcV4mWgAAADGhBQAAEBNaAAAAMTtacHG359/tzgEwkp0szsRECwAAICa0AAAAYo4O8p9Hx8bKcb63eweAa3I8cA5ee+3PRAsAACAmtAAAAGJCCwAAIGZH62J+ch53+2+dsX6de783u3MAzGzU6wX3MEYz0QIAAIgJLQAAgJjQAgAAiNnROjnnk8/P7hwAMxl5H/K6h5mYaAEAAMSEFgAAQExoAQAAxOxoTcB54s/nuf08AOA47GTB10y0AAAAYkILAAAgJrQAAABidrSA/2t77t5ZeAB+/XrdXpb7DkdmogUAABATWgAAADFHB/m2kW/fyvdtj1n4vQHwU1c/KjjLvXTWnw9fM9ECAACICS0AAICY0AIAAIjZ0WI63lIcAMZ65U7SLPf5Wfaw7vEa6VhMtAAAAGJCCwAAICa0AAAAYna0AAB4GXtFnUd7ZX7WY5loAQAAxIQWAABATGgBAADE7GgxPc+MAIB97fkMKfdtrspECwAAICa0AAAAYo4OcjiOEgIAPOY101gmWgAAADGhBQAAEBNaAAAAMTtaAAAX4+3c/zTLde/5u7n92rP8/56ZiRYAAEBMaAEAAMSEFgAAQMyOFofnGREAMI77bmv789xzZ4t9mWgBAADEhBYAAEBMaAEAAMTsaDHEnuePPSMCADiL29cy9rWOxUQLAAAgJrQAAABiQgsAACBmR4tT84wtAABGMNECAACICS0AAICYo4NM4VVvXeooIQAAr2CiBQAAEBNaAAAAMaEFAAAQs6PFdLZ7U6/c2Xp0LQAA8B0mWgAAADGhBQAAEBNaAAAAMTtaTO+VO1tbt9/LvhYAR/bK+ydgogUAAJATWgAAADGhBQAAELOjxeGM2tnafh87WwBclXsgPGaiBQAAEBNaAAAAMaEFAAAQs6PF4c2ys7Xl/DoAI3luFoxlogUAABATWgAAADFHBzmde0f2XnmMwtvBAwBcl4kWAABATGgBAADEhBYAAEDMjhaXMuqt4B99L/tbAMzMfWocb9N/XCZaAAAAMaEFAAAQE1oAAAAxO1pc2sidrXvf11l4ADgHO1bXZaIFAAAQE1oAAAAxoQUAABCzowU37u1GjXzmlp0tAHjMPhQzMdECAACICS0AAICY0AIAAIjZ0YJvGvnMLTtbAMBPef3wWiZaAAAAMaEFAAAQc3QQ/tKj8fueRwtvv7ZjAADAV7xGGMtECwAAICa0AAAAYkILAAAgZkcLdvKqt4N/5dvMAwDj2Lk6FhMtAACAmNACAACICS0AAICYHS2+rdw52v7bK5w5vv1/tFcFAHzlCq+JrsJECwAAICa0AAAAYkILAAAgZkcLBnjVM7YAuA73ktftN+35s77iHvtZmWgBAADEhBYAAEBMaAEAAMTsaMEE7GwBMBN7Qfe98r59+7X9Xo7FRAsAACAmtAAAAGKODsKEHCUEgONw3+YrJloAAAAxoQUAABATWgAAADE7WkzBW5fe5+w3ABzH7X27vGdvv5bXTHMz0QIAAIgJLQAAgJjQAgAAiNnR4q/tdf6Yx0b97J0NB4Dn7Lln7b48NxMtAACAmNACAACICS0AAICY0AIAAIgJLQAAgJjQAgAAiHl7d6bjrUoBgLPa8+3emYuJFgAAQExoAQAAxIQWAABAzI4WiT3PG9vZ+pPz3AAAczPRAgAAiAktAACAmNACAACI2dHicOxsAQAwOxMtAACAmNACAACICS0AAICYHS0O7wo7W56bBQBwLCZaAAAAMaEFAAAQE1oAAAAxO1rsYrsn9codo9vvddR9LTtZAADHZqIFAAAQE1oAAAAxRwd5iVFHCWd663fHAQEArsNECwAAICa0AAAAYkILAAAgZkeLIWbZ2bqCkW+1DwBwVSZaAAAAMaEFAAAQE1oAAAAxO1pM4d7zrewUPWfks8IAAPiHiRYAAEBMaAEAAMSEFgAAQMyOFtPzHKj77GQBAMzHRAsAACAmtAAAAGJCCwAAIGZHi8Oxs/XcXtaeP5/brz3Trtis1wUAXIeJFgAAQExoAQAAxBwd5PDuHQ07yrFCx9ue88zv9dHn+tkDAHsw0QIAAIgJLQAAgJjQAgAAiNnR4tTs37zOUfbhAHhs+zfd/RSeZ6IFAAAQE1oAAAAxoQUAABCzowUAcALbPSq7szCWiRYAAEBMaAEAAMSEFgAAQMyOFgAAd3muFjzPRAsAACAmtAAAAGJCCwAAIGZHCzg1ewQAvdudLX9n4WsmWgAAADGhBQAAEHN0EDgdx1gA/vxbuH2Ldsbwe7gOEy0AAICY0AIAAIgJLQAAgJgdLTi5o5zRt1cFsK/bv7PlvWD7tfw9fx0/67mZaAEAAMSEFgAAQExoAQAAxOxowcXMsrPlXDnAOHveC+xswT9MtAAAAGJCCwAAICa0AAAAYna04OKcnQdgT4/2v9yHOCsTLQAAgJjQAgAAiDk6CABwcSMf/XHvezlWyJGZaAEAAMSEFgAAQExoAQAAxOxoAQDwycidrRm+LxRMtAAAAGJCCwAAICa0AAAAYna0AAC4a5adLTgSEy0AAICY0AIAAIgJLQAAgJgdLQAAnrLd2bplf2s/937uzMdECwAAICa0AAAAYkILAAAgZkcLAIDMoz0iO1zPsZd1XCZaAAAAMaEFAAAQc3QQAICX8dbw9zkqeB4mWgAAADGhBQAAEBNaAAAAMTtaAABMwX4SZ2KiBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAACxZV3X73/ysnys6/q+4/UAwOG4PwKw9VRoAQAA8JijgwAAADGhBQAAEBNaAAAAMaEFAAAQE1oAAAAxoQUAABATWgAAADGhBQAAEBNaAAAAsf8B/EMy0ryMULEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x149d19320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = b.shape[0]\n",
    "print(d)\n",
    "fig, axes = plt.subplots(dim, 2, sharey=True, figsize=(15, 60), frameon=False)\n",
    "for i in range(dim):\n",
    "    plot_tick_free_axis(axes[i, 0], b[i, :, :, 0])\n",
    "    plot_tick_free_axis(axes[i, 1], c[i, :, :, 0])\n",
    "    #axes[i, 0].spines[\"top\"].set_visible(False)\n",
    "    #axes[i, 0].axes.get_xaxis().set_ticks([])\n",
    "    #axes[i, 0].axes.get_yaxis().set_ticks([])\n",
    "    #axes[i, 0].spines[\"right\"].set_visible(False)\n",
    "    #axes[i, 0].spines[\"bottom\"].set_visible(False)\n",
    "    #axes[i, 0].spines[\"left\"].set_visible(False)\n",
    "    #axes[i, 0].imshow(1 - b[i, :, :, 0], cmap='Greys')\n",
    "    #axes[i, 1].spines[\"top\"].set_visible(False)\n",
    "    #axes[i, 1].spines[\"right\"].set_visible(False)\n",
    "    #axes[i, 1].spines[\"bottom\"].set_visible(False)\n",
    "    #axes[i, 1].spines[\"left\"].set_visible(False)\n",
    "    #axes[i, 1].imshow(1 - c[i, :, :, 0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_inds, train_inds), (u, v) = a.generate_one_shot(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Malay_(Jawi_-_Arabic)', 'character11', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character11', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character16', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character16', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character29', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character29', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character20', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character20', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character27', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character27', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character18', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character18', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character26', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character26', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character19', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character19', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character21', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character21', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character17', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character17', '05'],\n",
       "       ['Malay_(Jawi_-_Arabic)', 'character28', '08',\n",
       "        'Malay_(Jawi_-_Arabic)', 'character28', '05']], dtype='<U41')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((y_train[test_inds], y_train[train_inds]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_20_shot = y_train_pd.iloc[:2500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gujarati:  48\n",
      "Korean:  40\n",
      "Arcadian:  26\n",
      "Malay_(Jawi_-_Arabic):  11\n"
     ]
    }
   ],
   "source": [
    "for alphabet in y_train_pd.iloc[:2500].Alphabet.unique():\n",
    "    print(alphabet + ': ', y_20_shot[y_20_shot.Alphabet == alphabet].Character.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest number of characters in a training alphabet: 14\n"
     ]
    }
   ],
   "source": [
    "alphabet_lengths = []\n",
    "for alphabet in y_train_pd.Alphabet.unique():\n",
    "    characters = y_train_pd.Character[y_train_pd.Alphabet == alphabet].unique()\n",
    "    alphabet_lengths.append(characters.shape[0])\n",
    "print(\"Smallest number of characters in a training alphabet: {}\".format(np.min(alphabet_lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_npz_file = np.load('../data/processed/test.npz')\n",
    "X_test, y_test = test_npz_file['arr_0'], test_npz_file['arr_1']\n",
    "y_test_pd = pd.DataFrame(data=y_test, columns=['Alphabet', 'Character', 'Drawer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest number of characters in a test alphabet: 20\n"
     ]
    }
   ],
   "source": [
    "alphabet_lengths = []\n",
    "for alphabet in y_test_pd.Alphabet.unique():\n",
    "    characters = y_test_pd.Character[y_test_pd.Alphabet == alphabet].unique()\n",
    "    alphabet_lengths.append(characters.shape[0])\n",
    "print(\"Smallest number of characters in a test alphabet: {}\".format(np.min(alphabet_lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19280, 3), (13180, 3), 32460)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd.shape, y_test_pd.shape, y_train_pd.shape[0] + y_test_pd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd.Alphabet.unique().shape[0] + y_test_pd.Alphabet.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_in_test, characters_in_train = 0, 0\n",
    "for alphabet in y_train_pd.Alphabet.unique():\n",
    "    characters_in_alphabet = y_train_pd.Character[\n",
    "                y_train_pd.Alphabet == alphabet\n",
    "            ].unique().shape[0]\n",
    "    characters_in_train += characters_in_alphabet\n",
    "characters_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for alphabet in y_test_pd.Alphabet.unique():\n",
    "    characters_in_alphabet = y_test_pd.Character[\n",
    "                y_test_pd.Alphabet == alphabet\n",
    "            ].unique().shape[0]\n",
    "    characters_in_test += characters_in_alphabet\n",
    "characters_in_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1623"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "964 + 659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.max(), X_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ost = OneShotGenerator(X_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 6, 28, 45, 76, 85]), array([ 1, 30, 42, 78, 90])),\n",
       " (    Alphabet    Character Drawer\n",
       "  6   Gujarati  character42     02\n",
       "  28  Gujarati  character45     02\n",
       "  45  Gujarati  character11     02\n",
       "  76  Gujarati  character16     02\n",
       "  85  Gujarati  character29     02,     Alphabet    Character Drawer\n",
       "  1   Gujarati  character42     01\n",
       "  30  Gujarati  character45     01\n",
       "  42  Gujarati  character11     01\n",
       "  78  Gujarati  character16     01\n",
       "  90  Gujarati  character29     01))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ost.generate_one_shot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([18, 23, 58, 60, 84]), array([16, 21, 57, 63, 81])),\n",
       " (    Alphabet    Character Drawer\n",
       "  18  Gujarati  character42     18\n",
       "  23  Gujarati  character45     18\n",
       "  58  Gujarati  character11     18\n",
       "  60  Gujarati  character16     18\n",
       "  84  Gujarati  character29     18,     Alphabet    Character Drawer\n",
       "  16  Gujarati  character42     20\n",
       "  21  Gujarati  character45     20\n",
       "  57  Gujarati  character11     20\n",
       "  63  Gujarati  character16     20\n",
       "  81  Gujarati  character29     20))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ost.cache[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ost.current_task_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((array([15, 20, 55, 62, 82]), array([ 8, 37, 47, 70, 98])),\n",
       "  (    Alphabet    Character Drawer\n",
       "   15  Gujarati  character42     09\n",
       "   20  Gujarati  character45     09\n",
       "   55  Gujarati  character11     09\n",
       "   62  Gujarati  character16     09\n",
       "   82  Gujarati  character29     09,     Alphabet    Character Drawer\n",
       "   8   Gujarati  character42     12\n",
       "   37  Gujarati  character45     12\n",
       "   47  Gujarati  character11     12\n",
       "   70  Gujarati  character16     12\n",
       "   98  Gujarati  character29     12)),\n",
       " 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ost.generate_one_shot(), ost.current_task_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd.Drawer.iloc[:40].isin(['03', '05', '16']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how to run Bayesian optimization using the GPyOpt library on cross validation score.  So we need to try to extend this basic example to maximize the validation score (maybe average over an epoch; in this case, change the default of 5 for each iteration where validation score is calculated to speed things up a bit).  \n",
    "\n",
    "So, for a setting of parameters we need a function which will:\n",
    "- Construct a model and optimizer with the given parameters.\n",
    "- Train the model (here train for a maximum of 200 epochs, cutting training if validation score has consistently increased for 20 epochs or something like this.\n",
    "- Save the trained model (with a name indicating the parameter values).\n",
    "- Evaluate the validation score of the trained model, and output this.\n",
    "\n",
    "Then this function will be passed to the Bayesian optimization engine and we will have saved the best model that it finds (this is important, because we don't want to re-train for a given set of parameters).     "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bds = [{'name': 'learning_rate', 'type': 'continuous', 'domain': (0, 1)},\n",
    "        {'name': 'gamma', 'type': 'continuous', 'domain': (0, 5)},\n",
    "        {'name': 'max_depth', 'type': 'discrete', 'domain': (1, 50)},\n",
    "        {'name': 'n_estimators', 'type': 'discrete', 'domain': (1, 300)},\n",
    "        {'name': 'min_child_weight', 'type': 'discrete', 'domain': (1, 10)}]\n",
    "\n",
    "# Optimization objective \n",
    "def cv_score(parameters):\n",
    "    parameters = parameters[0]\n",
    "    score = cross_val_score(\n",
    "                XGBRegressor(learning_rate=parameters[0],\n",
    "                              gamma=int(parameters[1]),\n",
    "                              max_depth=int(parameters[2]),\n",
    "                              n_estimators=int(parameters[3]),\n",
    "                              min_child_weight = parameters[4]), \n",
    "                X, Y, scoring='neg_mean_squared_error').mean()\n",
    "    score = np.array(score)\n",
    "    return score\n",
    "\n",
    "optimizer = BayesianOptimization(f=cv_score, \n",
    "                                 domain=bds,\n",
    "                                 model_type='GP',\n",
    "                                 acquisition_type ='EI',\n",
    "                                 acquisition_jitter = 0.05,\n",
    "                                 exact_feval=True, \n",
    "                                 maximize=True)\n",
    "\n",
    "# Only 20 iterations because we have 5 initial random points\n",
    "optimizer.run_optimization(max_iter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other (modelling) things that might be interesting to do while this is training on the big machine:\n",
    "- Get matching networks going in a colab environment so that we can train those things as well. Maybe experiment with different architectures here.  \n",
    "- While both of these are training, get nearest neighbors going on raw shape-contexts (sparsified?) and see how this does...  Doesn't need to be super fast, because for any given image we are only comparing against the support set.\n",
    "- Work on some graphics...  Plotting characters to illustrate the 20-shot task, etc. Also, something worth looking into would be getting tensorboard going within the optimizer so that we can look at the training process of these things and some other interesting things.\n",
    "- Try to start writing the notebook and setup the final git repository so that it can be shared soon.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'numpy.float64'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Encode categorical integer features using a one-hot aka one-of-K scheme.\n",
       "\n",
       "The input to this transformer should be a matrix of integers, denoting\n",
       "the values taken on by categorical (discrete) features. The output will be\n",
       "a sparse matrix where each column corresponds to one possible value of one\n",
       "feature. It is assumed that input features take on values in the range\n",
       "[0, n_values).\n",
       "\n",
       "This encoding is needed for feeding categorical data to many scikit-learn\n",
       "estimators, notably linear models and SVMs with the standard kernels.\n",
       "\n",
       "Note: a one-hot encoding of y labels should use a LabelBinarizer\n",
       "instead.\n",
       "\n",
       "Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_values : 'auto', int or array of ints\n",
       "    Number of values per feature.\n",
       "\n",
       "    - 'auto' : determine value range from training data.\n",
       "    - int : number of categorical values per feature.\n",
       "            Each feature value should be in ``range(n_values)``\n",
       "    - array : ``n_values[i]`` is the number of categorical values in\n",
       "              ``X[:, i]``. Each feature value should be\n",
       "              in ``range(n_values[i])``\n",
       "\n",
       "categorical_features : \"all\" or array of indices or mask\n",
       "    Specify what features are treated as categorical.\n",
       "\n",
       "    - 'all' (default): All features are treated as categorical.\n",
       "    - array of indices: Array of categorical feature indices.\n",
       "    - mask: Array of length n_features and with dtype=bool.\n",
       "\n",
       "    Non-categorical features are always stacked to the right of the matrix.\n",
       "\n",
       "dtype : number type, default=np.float\n",
       "    Desired dtype of output.\n",
       "\n",
       "sparse : boolean, default=True\n",
       "    Will return sparse matrix if set True else will return an array.\n",
       "\n",
       "handle_unknown : str, 'error' or 'ignore'\n",
       "    Whether to raise an error or ignore if a unknown categorical feature is\n",
       "    present during transform.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "active_features_ : array\n",
       "    Indices for active features, meaning values that actually occur\n",
       "    in the training set. Only available when n_values is ``'auto'``.\n",
       "\n",
       "feature_indices_ : array of shape (n_features,)\n",
       "    Indices to feature ranges.\n",
       "    Feature ``i`` in the original data is mapped to features\n",
       "    from ``feature_indices_[i]`` to ``feature_indices_[i+1]``\n",
       "    (and then potentially masked by `active_features_` afterwards)\n",
       "\n",
       "n_values_ : array of shape (n_features,)\n",
       "    Maximum number of values per feature.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Given a dataset with three features and four samples, we let the encoder\n",
       "find the maximum value per feature and transform the data to a binary\n",
       "one-hot encoding.\n",
       "\n",
       ">>> from sklearn.preprocessing import OneHotEncoder\n",
       ">>> enc = OneHotEncoder()\n",
       ">>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])  # doctest: +ELLIPSIS\n",
       "OneHotEncoder(categorical_features='all', dtype=<... 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)\n",
       ">>> enc.n_values_\n",
       "array([2, 3, 4])\n",
       ">>> enc.feature_indices_\n",
       "array([0, 2, 5, 9])\n",
       ">>> enc.transform([[0, 1, 1]]).toarray()\n",
       "array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.]])\n",
       "\n",
       "See also\n",
       "--------\n",
       "sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n",
       "  dictionary items (also handles string-valued features).\n",
       "sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n",
       "  encoding of dictionary items or strings.\n",
       "sklearn.preprocessing.LabelBinarizer : binarizes labels in a one-vs-all\n",
       "  fashion.\n",
       "sklearn.preprocessing.MultiLabelBinarizer : transforms between iterable of\n",
       "  iterables and a multilabel format, e.g. a (samples x classes) binary\n",
       "  matrix indicating the presence of a class label.\n",
       "sklearn.preprocessing.LabelEncoder : encodes labels with values between 0\n",
       "  and n_classes-1.\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Gujarati'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-cfdaa945eca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTestOneHot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m TestOneHot.fit(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \"\"\"\n\u001b[0;32m-> 1956\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \"\"\"\n\u001b[1;32m   2018\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 2019\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1807\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m     \"\"\"\n\u001b[0;32m-> 1809\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Gujarati'"
     ]
    }
   ],
   "source": [
    "TestOneHot = OneHotEncoder(sparse=False)\n",
    "TestOneHot.fit(\n",
    "        y_train[np.random.permutation(800)[:5]][:, :2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_train = np.array(\n",
    "    [x[0] + '_' + x[1] for x in y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gujarati_character42', 'Gujarati_character42',\n",
       "       'Gujarati_character42', 'Gujarati_character42',\n",
       "       'Gujarati_character42'], dtype='<U53')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Gujarati', 'character42', '14'],\n",
       "       ['Gujarati', 'character42', '01'],\n",
       "       ['Gujarati', 'character42', '15'],\n",
       "       ['Gujarati', 'character42', '03'],\n",
       "       ['Gujarati', 'character42', '17']], dtype='<U41')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Gujarati_character33'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-2182e6de3d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_y_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_y_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m TestOneHot.fit(\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mtest_y_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \"\"\"\n\u001b[0;32m-> 1956\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \"\"\"\n\u001b[1;32m   2018\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 2019\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1807\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m     \"\"\"\n\u001b[0;32m-> 1809\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Gujarati_character33'"
     ]
    }
   ],
   "source": [
    "test_y_values = new_y_train[np.random.permutation(800)[:50]]\n",
    "TestOneHot.fit(\n",
    "      test_y_values \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Transform between iterable of iterables and a multilabel format\n",
       "\n",
       "Although a list of sets or tuples is a very intuitive format for multilabel\n",
       "data, it is unwieldy to process. This transformer converts between this\n",
       "intuitive format and the supported multilabel format: a (samples x classes)\n",
       "binary matrix indicating the presence of a class label.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "classes : array-like of shape [n_classes] (optional)\n",
       "    Indicates an ordering for the class labels\n",
       "\n",
       "sparse_output : boolean (default: False),\n",
       "    Set to true if output binary array is desired in CSR sparse format\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : array of labels\n",
       "    A copy of the `classes` parameter where provided,\n",
       "    or otherwise, the sorted set of classes found when fitting.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.preprocessing import MultiLabelBinarizer\n",
       ">>> mlb = MultiLabelBinarizer()\n",
       ">>> mlb.fit_transform([(1, 2), (3,)])\n",
       "array([[1, 1, 0],\n",
       "       [0, 0, 1]])\n",
       ">>> mlb.classes_\n",
       "array([1, 2, 3])\n",
       "\n",
       ">>> mlb.fit_transform([set(['sci-fi', 'thriller']), set(['comedy'])])\n",
       "array([[0, 1, 1],\n",
       "       [1, 0, 0]])\n",
       ">>> list(mlb.classes_)\n",
       "['comedy', 'sci-fi', 'thriller']\n",
       "\n",
       "See also\n",
       "--------\n",
       "sklearn.preprocessing.OneHotEncoder : encode categorical integer features\n",
       "    using a one-hot aka one-of-K scheme.\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "MultiLabelBinarizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestOneHot = MultiLabelBinarizer()\n",
    "TestOneHot.fit(\n",
    "      [set(x) for x in np.unique(test_y_values)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'G', '_', 'a',\n",
       "       'c', 'e', 'h', 'i', 'j', 'r', 't', 'u'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestOneHot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gujarati_character03', 'Gujarati_character04',\n",
       "       'Gujarati_character05', 'Gujarati_character11',\n",
       "       'Gujarati_character12', 'Gujarati_character13',\n",
       "       'Gujarati_character14', 'Gujarati_character15',\n",
       "       'Gujarati_character17', 'Gujarati_character18',\n",
       "       'Gujarati_character19', 'Gujarati_character21',\n",
       "       'Gujarati_character22', 'Gujarati_character23',\n",
       "       'Gujarati_character26', 'Gujarati_character28',\n",
       "       'Gujarati_character31', 'Gujarati_character32',\n",
       "       'Gujarati_character33', 'Gujarati_character35',\n",
       "       'Gujarati_character36', 'Gujarati_character40',\n",
       "       'Gujarati_character41', 'Gujarati_character42',\n",
       "       'Gujarati_character43', 'Gujarati_character44',\n",
       "       'Gujarati_character45', 'Gujarati_character46',\n",
       "       'Gujarati_character47', 'Gujarati_character48'], dtype='<U53')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'G'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-025cf99c42d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTestOneHot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mclass_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, y, class_mapping)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'G'"
     ]
    }
   ],
   "source": [
    "TestOneHot.transform(test_y_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, encodings = LabelEncoder(), OneHotEncoder(sparse=False)\n",
    "\n",
    "encoded_ys = encodings.fit_transform(\n",
    "            labels.fit_transform(test_y_values).reshape(-1, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 30)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_ys[:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4633,  0.3179],\n",
       "        [ 0.1690, -0.2112],\n",
       "        [-0.7685,  1.0819],\n",
       "        [-0.3659, -2.0365],\n",
       "        [-0.7628, -0.0598]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, im_dim, n_channels, n_way = 32, 105, 1, 20\n",
    "\n",
    "x = torch.randn(batch_size, im_dim, im_dim, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=1, \n",
    "                    out_channels=64,\n",
    "                    kernel_size=5\n",
    "                ),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(2),\n",
    "                torch.nn.Dropout2d(),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, \n",
    "                    out_channels=128,\n",
    "                    kernel_size=3\n",
    "                ),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(2),\n",
    "                torch.nn.Dropout2d(),\n",
    "                Flatten(),\n",
    "                torch.nn.Linear(73728, 128) #int(128 * 3 * 3 / 4), 128)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randn(batch_size, n_channels, im_dim, im_dim)\n",
    "support_set = torch.randn(batch_size, n_way, n_channels, im_dim, im_dim)\n",
    "support_set_classes = torch.randn(batch_size, n_way, n_way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 32, 128]) torch.Size([20, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "repeats = [1 for _ in range(128)]\n",
    "repeats[0] = n_way\n",
    "target_embedding = encoder(target)\n",
    "support_set_embeddings = torch.stack(\n",
    "        [encoder(support_set[:, i, :, :, :]) for i in range(n_way)],\n",
    "    )\n",
    "print(support_set_embeddings.size(), \n",
    "      target_embedding.repeat([n_way, 1, 1]).size())\n",
    "similarities = cos(\n",
    "            target_embedding.repeat([n_way, 1, 1]), \n",
    "            support_set_embeddings\n",
    "  ).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "softmax_sims = softmax(similarities)\n",
    "print(softmax_sims.shape)\n",
    "preds = softmax_sims.unsqueeze(1).bmm(support_set_classes).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = torch.rand(batch_size, n_way)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = torch.randn(5, 3), torch.randn(5, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elementwise_mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "This criterion combines :func:`nn.LogSoftmax` and :func:`nn.NLLLoss` in one single class.\n",
       "\n",
       "It is useful when training a classification problem with `C` classes.\n",
       "If provided, the optional argument :attr:`weight` should be a 1D `Tensor`\n",
       "assigning weight to each of the classes.\n",
       "This is particularly useful when you have an unbalanced training set.\n",
       "\n",
       "The `input` is expected to contain scores for each class.\n",
       "\n",
       "`input` has to be a Tensor of size either :math:`(minibatch, C)` or\n",
       ":math:`(minibatch, C, d_1, d_2, ..., d_K)`\n",
       "with :math:`K \\geq 2` for the `K`-dimensional case (described later).\n",
       "\n",
       "This criterion expects a class index (0 to `C-1`) as the\n",
       "`target` for each value of a 1D tensor of size `minibatch`\n",
       "\n",
       "The loss can be described as:\n",
       "\n",
       ".. math::\n",
       "    \\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)\n",
       "                   = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\n",
       "\n",
       "or in the case of the `weight` argument being specified:\n",
       "\n",
       ".. math::\n",
       "    \\text{loss}(x, class) = weight[class] \\left(-x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\\right)\n",
       "\n",
       "The losses are averaged across observations for each minibatch.\n",
       "\n",
       "Can also be used for higher dimension inputs, such as 2D images, by providing\n",
       "an input of size :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 2`,\n",
       "where :math:`K` is the number of dimensions, and a target of appropriate shape\n",
       "(see below).\n",
       "\n",
       "\n",
       "Args:\n",
       "    weight (Tensor, optional): a manual rescaling weight given to each class.\n",
       "        If given, has to be a Tensor of size `C`\n",
       "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
       "        the losses are averaged over each loss element in the batch. Note that for\n",
       "        some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
       "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
       "        when reduce is ``False``. Default: ``True``\n",
       "    ignore_index (int, optional): Specifies a target value that is ignored\n",
       "        and does not contribute to the input gradient. When `size_average` is\n",
       "        ``True``, the loss is averaged over non-ignored targets.\n",
       "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
       "        losses are averaged or summed over observations for each minibatch depending\n",
       "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
       "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
       "    reduction (string, optional): Specifies the reduction to apply to the output:\n",
       "        'none' | 'elementwise_mean' | 'sum'. 'none': no reduction will be applied,\n",
       "        'elementwise_mean': the sum of the output will be divided by the number of\n",
       "        elements in the output, 'sum': the output will be summed. Note: :attr:`size_average`\n",
       "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
       "        specifying either of those two args will override :attr:`reduction`. Default: 'elementwise_mean'\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C)` where `C = number of classes`, or\n",
       "        :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 2`\n",
       "        in the case of `K`-dimensional loss.\n",
       "    - Target: :math:`(N)` where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or\n",
       "        :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 2` in the case of\n",
       "        K-dimensional loss.\n",
       "    - Output: scalar. If reduce is ``False``, then the same size\n",
       "        as the target: :math:`(N)`, or\n",
       "        :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 2` in the case\n",
       "        of K-dimensional loss.\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> loss = nn.CrossEntropyLoss()\n",
       "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
       "    >>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
       "    >>> output = loss(input, target)\n",
       "    >>> output.backward()\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies a 2D convolution over an input signal composed of several input\n",
       "planes.\n",
       "\n",
       "In the simplest case, the output value of the layer with input size\n",
       ":math:`(N, C_{in}, H, W)` and output :math:`(N, C_{out}, H_{out}, W_{out})`\n",
       "can be precisely described as:\n",
       "\n",
       ".. math::\n",
       "\n",
       "    \\begin{equation*}\n",
       "    \\text{out}(N_i, C_{out_j}) = \\text{bias}(C_{out_j}) +\n",
       "                            \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{out_j}, k) \\star \\text{input}(N_i, k)\n",
       "    \\end{equation*},\n",
       "\n",
       "where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
       ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
       ":math:`H` is a height of input planes in pixels, and :math:`W` is\n",
       "width in pixels.\n",
       "\n",
       "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
       "  number or a tuple.\n",
       "\n",
       "* :attr:`padding` controls the amount of implicit zero-paddings on both\n",
       "  sides for :attr:`padding` number of points for each dimension.\n",
       "\n",
       "* :attr:`dilation` controls the spacing between the kernel points; also\n",
       "  known as the  trous algorithm. It is harder to describe, but this `link`_\n",
       "  has a nice visualization of what :attr:`dilation` does.\n",
       "\n",
       "* :attr:`groups` controls the connections between inputs and outputs.\n",
       "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
       "  :attr:`groups`. For example,\n",
       "\n",
       "    * At groups=1, all inputs are convolved to all outputs.\n",
       "    * At groups=2, the operation becomes equivalent to having two conv\n",
       "      layers side by side, each seeing half the input channels,\n",
       "      and producing half the output channels, and both subsequently\n",
       "      concatenated.\n",
       "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
       "      its own set of filters (of size\n",
       "      :math:`\\left\\lfloor\\frac{\\text{out_channels}}{\\text{in_channels}}\\right\\rfloor`).\n",
       "\n",
       "The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
       "\n",
       "    - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
       "    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
       "      and the second `int` for the width dimension\n",
       "\n",
       ".. note::\n",
       "\n",
       "     Depending of the size of your kernel, several (of the last)\n",
       "     columns of the input might be lost, because it is a valid `cross-correlation`_,\n",
       "     and not a full `cross-correlation`_.\n",
       "     It is up to the user to add proper padding.\n",
       "\n",
       ".. note::\n",
       "\n",
       "     The configuration when `groups == in_channels` and `out_channels == K * in_channels`\n",
       "     where `K` is a positive integer is termed in literature as depthwise convolution.\n",
       "\n",
       "     In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`, if you want a\n",
       "     depthwise convolution with a depthwise multiplier `K`,\n",
       "     then you use the constructor arguments\n",
       "     :math:`(\\text{in_channels}=C_{in}, \\text{out_channels}=C_{in} * K, ..., \\text{groups}=C_{in})`\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Number of channels in the input image\n",
       "    out_channels (int): Number of channels produced by the convolution\n",
       "    kernel_size (int or tuple): Size of the convolving kernel\n",
       "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
       "    padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
       "    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
       "    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n",
       "    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n",
       "    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n",
       "\n",
       "      .. math::\n",
       "          H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
       "                    \\times (\\text{kernel_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
       "\n",
       "          W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
       "                    \\times (\\text{kernel_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape\n",
       "                     (out_channels, in_channels, kernel_size[0], kernel_size[1])\n",
       "    bias (Tensor):   the learnable bias of the module of shape (out_channels)\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> # With square kernels and equal stride\n",
       "    >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
       "    >>> # non-square kernels and unequal stride and with padding\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
       "    >>> # non-square kernels and unequal stride and with padding and dilation\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
       "    >>> input = torch.randn(20, 16, 50, 100)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _cross-correlation:\n",
       "    https://en.wikipedia.org/wiki/Cross-correlation\n",
       "\n",
       ".. _link:\n",
       "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.nn.Conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4704, -0.3899,  1.9540,  0.3998,  0.4787, -0.4517],\n",
       "        [-2.0221, -0.0392, -1.6051, -0.2426, -0.0655,  0.3696]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.randn(6) for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0346,  0.7960, -0.6996],\n",
       "        [-0.3793,  0.1917,  0.8055],\n",
       "        [ 1.2832,  1.4354, -1.6485],\n",
       "        [-1.2324, -1.5399, -3.0186],\n",
       "        [ 1.6849, -1.5136,  0.2635],\n",
       "        [ 0.0346,  0.7960, -0.6996],\n",
       "        [-0.3793,  0.1917,  0.8055],\n",
       "        [ 1.2832,  1.4354, -1.6485],\n",
       "        [-1.2324, -1.5399, -3.0186],\n",
       "        [ 1.6849, -1.5136,  0.2635]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.repeat(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "bmm(batch2) -> Tensor\n",
       "\n",
       "See :func:`torch.bmm`\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.bmm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "bmm(batch1, batch2, out=None) -> Tensor\n",
       "\n",
       "Performs a batch matrix-matrix product of matrices stored in :attr:`batch1`\n",
       "and :attr:`batch2`.\n",
       "\n",
       ":attr:`batch1` and :attr:`batch2` must be 3-D tensors each containing\n",
       "the same number of matrices.\n",
       "\n",
       "If :attr:`batch1` is a :math:`(b \\times n \\times m)` tensor, :attr:`batch2` is a\n",
       ":math:`(b \\times m \\times p)` tensor, :attr:`out` will be a\n",
       ":math:`(b \\times n \\times p)` tensor.\n",
       "\n",
       ".. math::\n",
       "    out_i = batch1_i \\mathbin{@} batch2_i\n",
       "\n",
       ".. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
       "          For broadcasting matrix products, see :func:`torch.matmul`.\n",
       "\n",
       "Args:\n",
       "    batch1 (Tensor): the first batch of matrices to be multiplied\n",
       "    batch2 (Tensor): the second batch of matrices to be multiplied\n",
       "    out (Tensor, optional): the output tensor\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> batch1 = torch.randn(10, 3, 4)\n",
       "    >>> batch2 = torch.randn(10, 4, 5)\n",
       "    >>> res = torch.bmm(batch1, batch2)\n",
       "    >>> res.size()\n",
       "    torch.Size([10, 3, 5])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.bmm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "unsqueeze(input, dim, out=None) -> Tensor\n",
       "\n",
       "Returns a new tensor with a dimension of size one inserted at the\n",
       "specified position.\n",
       "\n",
       "The returned tensor shares the same underlying data with this tensor.\n",
       "\n",
       "A :attr:`dim` value within the range ``[-input.dim() - 1, input.dim() + 1)``\n",
       "can be used. Negative :attr:`dim` will correspond to :meth:`unsqueeze`\n",
       "applied at :attr:`dim` = ``dim + input.dim() + 1``.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor\n",
       "    dim (int): the index at which to insert the singleton dimension\n",
       "    out (Tensor, optional): the output tensor\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> x = torch.tensor([1, 2, 3, 4])\n",
       "    >>> torch.unsqueeze(x, 0)\n",
       "    tensor([[ 1,  2,  3,  4]])\n",
       "    >>> torch.unsqueeze(x, 1)\n",
       "    tensor([[ 1],\n",
       "            [ 2],\n",
       "            [ 3],\n",
       "            [ 4]])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.unsqueeze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(5).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-c4573cd01120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "u.bmm(torch.randn(5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1046],\n",
       "        [ 0.0557],\n",
       "        [-0.5311],\n",
       "        [-0.1422],\n",
       "        [ 0.3786]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u * torch.randn(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-11c6750a97bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "torch.randn(1, 5).bmm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5765],\n",
       "        [-0.2798],\n",
       "        [ 0.7478],\n",
       "        [-0.5178],\n",
       "        [ 0.6074]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4195, -0.1233, -0.1362,  1.0434,  0.8230]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "bmm(batch1, batch2, out=None) -> Tensor\n",
       "\n",
       "Performs a batch matrix-matrix product of matrices stored in :attr:`batch1`\n",
       "and :attr:`batch2`.\n",
       "\n",
       ":attr:`batch1` and :attr:`batch2` must be 3-D tensors each containing\n",
       "the same number of matrices.\n",
       "\n",
       "If :attr:`batch1` is a :math:`(b \\times n \\times m)` tensor, :attr:`batch2` is a\n",
       ":math:`(b \\times m \\times p)` tensor, :attr:`out` will be a\n",
       ":math:`(b \\times n \\times p)` tensor.\n",
       "\n",
       ".. math::\n",
       "    out_i = batch1_i \\mathbin{@} batch2_i\n",
       "\n",
       ".. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
       "          For broadcasting matrix products, see :func:`torch.matmul`.\n",
       "\n",
       "Args:\n",
       "    batch1 (Tensor): the first batch of matrices to be multiplied\n",
       "    batch2 (Tensor): the second batch of matrices to be multiplied\n",
       "    out (Tensor, optional): the output tensor\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> batch1 = torch.randn(10, 3, 4)\n",
       "    >>> batch2 = torch.randn(10, 4, 5)\n",
       "    >>> res = torch.bmm(batch1, batch2)\n",
       "    >>> res.size()\n",
       "    torch.Size([10, 3, 5])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.bmm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = torch.randn(5, 2), torch.randn(5, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2140, -1.8143, -1.3858],\n",
       "        [ 0.5442,  0.5898, -0.4103],\n",
       "        [-1.1018,  2.6175,  2.2155],\n",
       "        [ 1.2661,  0.5904, -2.2937],\n",
       "        [ 0.1823, -0.1176, -0.5553]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(1).bmm(b).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2139085930645466"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, :].data.numpy().dot([-0.1393, -0.0603])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36893488147419103232.)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, :].dot(torch.tensor([-0.1393, -0.0603]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1393,  0.7030,  0.4449],\n",
       "         [-0.0603,  1.5893,  1.4215]],\n",
       "\n",
       "        [[-2.4186,  0.5901,  0.1137],\n",
       "         [-0.5182, -0.4702,  0.3420]],\n",
       "\n",
       "        [[-0.9674, -1.9657, -2.5030],\n",
       "         [ 2.0719,  0.2152,  1.1932]],\n",
       "\n",
       "        [[-0.8588,  0.2411,  0.8915],\n",
       "         [ 0.1181,  0.4073, -0.5786]],\n",
       "\n",
       "        [[-0.7648,  0.4800,  1.4808],\n",
       "         [-0.5403,  0.3096, -0.8365]]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2881, -0.5718],\n",
       "         [ 0.0345, -1.2112],\n",
       "         [-1.4646, -1.2157],\n",
       "         [-1.1789,  2.1477],\n",
       "         [-0.3143,  0.1075]]), tensor([-1.2881, -0.5718]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2881, -0.5718]],\n",
       "\n",
       "        [[ 0.0345, -1.2112]],\n",
       "\n",
       "        [[-1.4646, -1.2157]],\n",
       "\n",
       "        [[-1.1789,  2.1477]],\n",
       "\n",
       "        [[-0.3143,  0.1075]]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 3])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(1).bmm(b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Implements Adam algorithm.\n",
       "\n",
       "It has been proposed in `Adam: A Method for Stochastic Optimization`_.\n",
       "\n",
       "Arguments:\n",
       "    params (iterable): iterable of parameters to optimize or dicts defining\n",
       "        parameter groups\n",
       "    lr (float, optional): learning rate (default: 1e-3)\n",
       "    betas (Tuple[float, float], optional): coefficients used for computing\n",
       "        running averages of gradient and its square (default: (0.9, 0.999))\n",
       "    eps (float, optional): term added to the denominator to improve\n",
       "        numerical stability (default: 1e-8)\n",
       "    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
       "    amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
       "        algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
       "\n",
       ".. _Adam\\: A Method for Stochastic Optimization:\n",
       "    https://arxiv.org/abs/1412.6980\n",
       ".. _On the Convergence of Adam and Beyond:\n",
       "    https://openreview.net/forum?id=ryQu7f-RZ\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.Adam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "An abstract class representing a Dataset.\n",
       "\n",
       "All other datasets should subclass it. All subclasses should override\n",
       "``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
       "supporting integer indexing in range from 0 to len(self) exclusive.\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/torch/utils/data/dataset.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mdefault_collate\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x10e723048\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Data loader. Combines a dataset and a sampler, and provides\n",
       "single- or multi-process iterators over the dataset.\n",
       "\n",
       "Arguments:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: 1).\n",
       "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
       "        at every epoch (default: False).\n",
       "    sampler (Sampler, optional): defines the strategy to draw samples from\n",
       "        the dataset. If specified, ``shuffle`` must be False.\n",
       "    batch_sampler (Sampler, optional): like sampler, but returns a batch of\n",
       "        indices at a time. Mutually exclusive with batch_size, shuffle,\n",
       "        sampler, and drop_last.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. 0 means that the data will be loaded in the main process.\n",
       "        (default: 0)\n",
       "    collate_fn (callable, optional): merges a list of samples to form a mini-batch.\n",
       "    pin_memory (bool, optional): If ``True``, the data loader will copy tensors\n",
       "        into CUDA pinned memory before returning them.\n",
       "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: False)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: 0)\n",
       "    worker_init_fn (callable, optional): If not None, this will be called on each\n",
       "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
       "        input, after seeding and before data loading. (default: None)\n",
       "\n",
       ".. note:: By default, each worker will have its PyTorch seed set to\n",
       "          ``base_seed + worker_id``, where ``base_seed`` is a long generated\n",
       "          by main process using its RNG. However, seeds for other libraies\n",
       "          may be duplicated upon initializing workers (w.g., NumPy), causing\n",
       "          each worker to return identical random numbers. (See\n",
       "          :ref:`dataloader-workers-random-seed` section in FAQ.) You may\n",
       "          use ``torch.initial_seed()`` to access the PyTorch seed for each\n",
       "          worker in :attr:`worker_init_fn`, and use it to set other seeds\n",
       "          before data loading.\n",
       "\n",
       ".. warning:: If ``spawn`` start method is used, :attr:`worker_init_fn` cannot be an\n",
       "             unpicklable object, e.g., a lambda function.\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        module\n",
       "\u001b[0;31mString form:\u001b[0m <module 'torch.utils.data.dataset' from '/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataset.py'>\n",
       "\u001b[0;31mFile:\u001b[0m        /anaconda3/lib/python3.6/site-packages/torch/utils/data/dataset.py\n",
       "\u001b[0;31mDocstring:\u001b[0m   <no docstring>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "An abstract class representing a Dataset.\n",
       "\n",
       "All other datasets should subclass it. All subclasses should override\n",
       "``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
       "supporting integer indexing in range from 0 to len(self) exclusive.\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.6/site-packages/torch/utils/data/dataset.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mkoudstaal/Documents/Projects/one-shot/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Directory tree generator.\n",
       "\n",
       "For each directory in the directory tree rooted at top (including top\n",
       "itself, but excluding '.' and '..'), yields a 3-tuple\n",
       "\n",
       "    dirpath, dirnames, filenames\n",
       "\n",
       "dirpath is a string, the path to the directory.  dirnames is a list of\n",
       "the names of the subdirectories in dirpath (excluding '.' and '..').\n",
       "filenames is a list of the names of the non-directory files in dirpath.\n",
       "Note that the names in the lists are just names, with no path components.\n",
       "To get a full path (which begins with top) to a file or directory in\n",
       "dirpath, do os.path.join(dirpath, name).\n",
       "\n",
       "If optional arg 'topdown' is true or not specified, the triple for a\n",
       "directory is generated before the triples for any of its subdirectories\n",
       "(directories are generated top down).  If topdown is false, the triple\n",
       "for a directory is generated after the triples for all of its\n",
       "subdirectories (directories are generated bottom up).\n",
       "\n",
       "When topdown is true, the caller can modify the dirnames list in-place\n",
       "(e.g., via del or slice assignment), and walk will only recurse into the\n",
       "subdirectories whose names remain in dirnames; this can be used to prune the\n",
       "search, or to impose a specific order of visiting.  Modifying dirnames when\n",
       "topdown is false is ineffective, since the directories in dirnames have\n",
       "already been generated by the time dirnames itself is generated. No matter\n",
       "the value of topdown, the list of subdirectories is retrieved before the\n",
       "tuples for the directory and its subdirectories are generated.\n",
       "\n",
       "By default errors from the os.scandir() call are ignored.  If\n",
       "optional arg 'onerror' is specified, it should be a function; it\n",
       "will be called with one argument, an OSError instance.  It can\n",
       "report the error to continue with the walk, or raise the exception\n",
       "to abort the walk.  Note that the filename is available as the\n",
       "filename attribute of the exception object.\n",
       "\n",
       "By default, os.walk does not follow symbolic links to subdirectories on\n",
       "systems that support them.  In order to get this functionality, set the\n",
       "optional argument 'followlinks' to true.\n",
       "\n",
       "Caution:  if you pass a relative pathname for top, don't change the\n",
       "current working directory between resumptions of walk.  walk never\n",
       "changes the current directory, and assumes that the client doesn't\n",
       "either.\n",
       "\n",
       "Example:\n",
       "\n",
       "import os\n",
       "from os.path import join, getsize\n",
       "for root, dirs, files in os.walk('python/Lib/email'):\n",
       "    print(root, \"consumes\", end=\"\")\n",
       "    print(sum([getsize(join(root, name)) for name in files]), end=\"\")\n",
       "    print(\"bytes in\", len(files), \"non-directory files\")\n",
       "    if 'CVS' in dirs:\n",
       "        dirs.remove('CVS')  # don't visit CVS directories\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/lib/python3.6/os.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.walk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mkoudstaal/Documents/Projects/one-shot/notebooks'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mkoudstaal/Documents/Projects/one-shot/src\n",
      "['visualization', 'features', 'models', 'data']\n",
      "['__init__.py']\n",
      "/Users/mkoudstaal/Documents/Projects/one-shot/src/visualization\n",
      "[]\n",
      "['.gitkeep', '__init__.py', 'visualize.py']\n",
      "/Users/mkoudstaal/Documents/Projects/one-shot/src/features\n",
      "[]\n",
      "['.gitkeep', 'build_features.py', '__init__.py']\n",
      "/Users/mkoudstaal/Documents/Projects/one-shot/src/models\n",
      "[]\n",
      "['train_model.py', '.gitkeep', '__init__.py', 'predict_model.py']\n",
      "/Users/mkoudstaal/Documents/Projects/one-shot/src/data\n",
      "[]\n",
      "['.DS_Store', '.gitkeep', '__init__.py', 'make_dataset.py', 'data_utils.py']\n"
     ]
    }
   ],
   "source": [
    "for (root, dirs, files) in os.walk('/Users/mkoudstaal/Documents/Projects/one-shot/src'):\n",
    "    print(root)\n",
    "    print(dirs)\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
